# qc-sampler

A vLLM V1 LogitsProcessor plugin that replaces standard pseudorandom token sampling with quantum-random sampling. It allows consciousness to influence token selection through quantum random number generators (QRNGs), based on the theory that consciousness can bias quantum-random outcomes.

## How it works

For each token generated by the language model:

1. **20,480 raw bytes** are fetched from a hardware QRNG via gRPC
2. A **z-score signal amplification** algorithm reduces those bytes to a single uniform float `u` in (0, 1)
3. That float drives token selection through a **probability-ordered CDF** (cumulative distribution function)

The CDF is sorted by descending probability, so `u` near 0 selects the most likely token and `u` near 1 selects increasingly surprising tokens. Under the null hypothesis (no consciousness influence), `u` is uniformly distributed and sampling behaves normally. Any bias in the QRNG output shifts `u` in a coherent semantic direction.

Optionally, an **entropy-based dynamic temperature (EDT)** system modulates temperature per-token based on Shannon entropy of the logit distribution. When the model is uncertain (high entropy), temperature increases for more diversity; when confident (low entropy), temperature decreases for more determinism.

## Quick start

### Prerequisites

- Python 3.10+
- A running vLLM V1 instance
- A QRNG gRPC server (see [gRPC server setup](#grpc-server-setup) below), or use the `os_urandom` fallback for testing

### Installation

```bash
pip install -e .
```

This registers the plugin with vLLM via the `vllm.logits_processors` entry point. vLLM will automatically discover and load it.

### Verify installation

```bash
python -c "
from importlib.metadata import entry_points
eps = entry_points(group='vllm.logits_processors')
for ep in eps:
    print(f'{ep.name} = {ep.value}')
"
```

You should see:

```
quantum_consciousness = qc_sampler.processor:QuantumConsciousnessProcessor
```

### Basic usage with vLLM

Because the plugin handles all sampling internally, set vLLM-level sampling parameters to pass-through:

```python
from vllm import LLM, SamplingParams

llm = LLM(model="your-model")

params = SamplingParams(
    temperature=1.0,     # no vLLM temperature scaling
    top_k=-1,            # no vLLM top-k
    top_p=1.0,           # no vLLM top-p
    max_tokens=2048,
    extra_args={
        "qc_temperature_strategy": "fixed",
        "qc_fixed_temperature": 0.7,
        "qc_top_k": 50,
        "qc_top_p": 0.9,
    }
)

output = llm.generate("Once upon a time", params)
```

### Using entropy-based dynamic temperature (EDT)

```python
params = SamplingParams(
    temperature=1.0,
    top_k=-1,
    top_p=1.0,
    max_tokens=2048,
    extra_args={
        "qc_temperature_strategy": "edt",
        "qc_edt_base_temp": 0.8,
        "qc_edt_exponent": 0.5,
        "qc_edt_min_temp": 0.1,
        "qc_edt_max_temp": 2.0,
        "qc_top_k": 50,
        "qc_top_p": 0.9,
    }
)
```

## gRPC server setup

The plugin fetches quantum random bytes from a remote QRNG server over gRPC. This section explains how to set up that connection.

### Protocol definition

The gRPC service is defined in `qc_sampler/proto/entropy_service.proto`:

```protobuf
syntax = "proto3";
package entropy;

service EntropyService {
  rpc GetEntropy (EntropyRequest) returns (EntropyResponse);
  rpc StreamEntropy (stream EntropyRequest) returns (stream EntropyResponse);
}

message EntropyRequest {
  int32 bytes_needed = 1;  // number of random bytes to generate
}

message EntropyResponse {
  bytes data = 1;           // the raw random bytes
  int64 timestamp_ns = 2;   // server timestamp (nanoseconds)
  string device_id = 3;     // identifier of the QRNG hardware device
}
```

### What your QRNG server needs to implement

Your gRPC server must implement the `EntropyService.GetEntropy` RPC. When called with `bytes_needed = 20480` (the default), it should return exactly 20,480 bytes of quantum random data in the `data` field.

The `StreamEntropy` RPC is defined for future streaming use but is not currently called by the plugin.

### Compiling the proto (for server-side)

If you're building the gRPC server, compile the proto file for your language:

```bash
# Python server example
python -m grpc_tools.protoc \
  -I qc_sampler/proto \
  --python_out=your_server/proto \
  --grpc_python_out=your_server/proto \
  qc_sampler/proto/entropy_service.proto

# Go server example
protoc \
  --go_out=. --go-grpc_out=. \
  qc_sampler/proto/entropy_service.proto
```

The plugin ships with pre-generated Python stubs (`entropy_service_pb2.py` and `entropy_service_pb2_grpc.py`), so you do not need to compile anything on the client side.

### Minimal Python gRPC server example

Here's a minimal example of a QRNG gRPC server for testing. Replace `os.urandom` with your actual hardware QRNG calls:

```python
"""Minimal QRNG gRPC server for testing."""

import os
import time
from concurrent import futures

import grpc

# Import the generated proto stubs (compile from entropy_service.proto)
import entropy_service_pb2
import entropy_service_pb2_grpc


class EntropyServicer(entropy_service_pb2_grpc.EntropyServiceServicer):
    def GetEntropy(self, request, context):
        # Replace os.urandom with your actual QRNG hardware call
        data = os.urandom(request.bytes_needed)
        return entropy_service_pb2.EntropyResponse(
            data=data,
            timestamp_ns=time.time_ns(),
            device_id="test-device-001",
        )


def serve():
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    entropy_service_pb2_grpc.add_EntropyServiceServicer_to_server(
        EntropyServicer(), server
    )
    server.add_insecure_port("[::]:50051")
    server.start()
    print("QRNG server listening on port 50051")
    server.wait_for_termination()


if __name__ == "__main__":
    serve()
```

### Connecting the plugin to your server

Set the server address via environment variable:

```bash
export QC_QRNG_SERVER_ADDRESS=10.0.1.5:50051
```

Or configure it in the environment before starting vLLM.

### Connection behavior

- The plugin maintains a **persistent gRPC channel** with keepalive pings
- On each token, it calls `GetEntropy(bytes_needed=20480)` (configurable via `QC_SAMPLE_COUNT`)
- If `QC_QRNG_PREFETCH_ENABLED=true` (default), bytes are fetched in a background thread during the GPU forward pass, so the gRPC latency is hidden behind model computation
- If the server is unreachable, the plugin retries up to `QC_QRNG_RETRY_COUNT` times (default: 2), then falls back based on `QC_QRNG_FALLBACK_MODE`

### Fallback modes

| Mode | Behavior |
|------|----------|
| `os_urandom` | Falls back to Python's `os.urandom()` (CSPRNG, not quantum). Default. |
| `mock_uniform` | Returns bytes centered around 127.5. For testing only. |
| `error` | Raises `EntropyUnavailableError`. No fallback. Use when quantum randomness is required. |

```bash
# Require quantum randomness — fail if QRNG server is down
export QC_QRNG_FALLBACK_MODE=error

# Allow CSPRNG fallback (default)
export QC_QRNG_FALLBACK_MODE=os_urandom
```

## Configuration

Every parameter is configurable via environment variables (system defaults) and per-request via `extra_args` (runtime overrides).

### Environment variables

Set these before starting vLLM. All use the `QC_` prefix:

| Variable | Type | Default | Description |
|----------|------|---------|-------------|
| `QC_QRNG_SERVER_ADDRESS` | str | `localhost:50051` | gRPC server address (host:port) |
| `QC_QRNG_TIMEOUT_MS` | float | `5000.0` | gRPC call timeout in milliseconds |
| `QC_QRNG_PREFETCH_ENABLED` | bool | `true` | Prefetch bytes during GPU forward pass |
| `QC_QRNG_RETRY_COUNT` | int | `2` | Retries before falling back |
| `QC_QRNG_FALLBACK_MODE` | str | `os_urandom` | `error`, `os_urandom`, or `mock_uniform` |
| `QC_SIGNAL_AMPLIFIER_TYPE` | str | `zscore_mean` | Signal amplification algorithm |
| `QC_SAMPLE_COUNT` | int | `20480` | Raw bytes per token |
| `QC_POPULATION_MEAN` | float | `127.5` | Expected mean of uniform uint8 |
| `QC_POPULATION_STD` | float | `73.6116` | Std dev of uniform uint8 (255/sqrt(12)) |
| `QC_UNIFORM_CLAMP_EPSILON` | float | `1e-10` | Clamp u away from 0 and 1 |
| `QC_TEMPERATURE_STRATEGY` | str | `fixed` | `fixed` or `edt` |
| `QC_FIXED_TEMPERATURE` | float | `0.7` | Temperature when strategy is `fixed` |
| `QC_EDT_MIN_TEMP` | float | `0.1` | EDT minimum temperature |
| `QC_EDT_MAX_TEMP` | float | `2.0` | EDT maximum temperature |
| `QC_EDT_BASE_TEMP` | float | `0.8` | EDT base temperature (T0) |
| `QC_EDT_EXPONENT` | float | `0.5` | EDT sensitivity exponent (theta) |
| `QC_TOP_K` | int | `50` | Top-k filtering (0 or negative = disabled) |
| `QC_TOP_P` | float | `0.9` | Nucleus sampling threshold (1.0 = disabled) |
| `QC_LOG_LEVEL` | str | `summary` | `none`, `summary`, or `full` |
| `QC_DIAGNOSTIC_MODE` | bool | `false` | Record all intermediate values in memory |

### Per-request overrides

Most parameters can be overridden per-request via `extra_args` with the `qc_` prefix. Infrastructure fields (`qrng_server_address`, `qrng_timeout_ms`, `qrng_prefetch_enabled`, `qrng_retry_count`, `qrng_fallback_mode`) cannot be overridden per-request.

```python
params = SamplingParams(
    temperature=1.0, top_k=-1, top_p=1.0,
    extra_args={
        "qc_temperature_strategy": "edt",
        "qc_edt_exponent": 0.8,
        "qc_top_k": 100,
        "qc_diagnostic_mode": True,
    }
)
```

## Logging and diagnostics

The plugin logs through Python's `logging` module under the `"qc_sampler"` logger.

### Log levels

- **`none`** — No per-token logging. Minimal overhead for production.
- **`summary`** — One line per token with key metrics: u-value, temperature, token rank, latency.
- **`full`** — Complete diagnostic dump including all intermediate values from every pipeline stage.

### Diagnostic mode

When `QC_DIAGNOSTIC_MODE=true`, the plugin stores every `TokenSamplingRecord` in memory regardless of log level. This enables offline statistical analysis:

```python
# Access diagnostic data programmatically
logger = processor._logger
records = logger.get_diagnostic_data()
u_values = [r.u_value for r in records]

# Get aggregate statistics
stats = logger.get_summary_stats()
```

Each record includes: timestamps, QRNG source used, sample mean, z-score, u-value, temperature strategy, Shannon entropy, temperature used, token ID, token rank, token probability, candidate count, and a config hash for reproducibility.

## Running tests

```bash
# Install dev dependencies
pip install -e ".[dev]"

# Run all tests
pytest tests/ -v

# Run specific test modules
pytest tests/test_config.py -v
pytest tests/test_signal_amplifier.py -v
pytest tests/test_temperature_strategy.py -v
pytest tests/test_token_selector.py -v
pytest tests/test_processor.py -v
pytest tests/test_statistical_properties.py -v
```

The statistical property tests (`test_statistical_properties.py`) require `scipy` and validate mathematical properties of the sampling pipeline, including KS-tests for uniformity of u-values under the null hypothesis.

## Architecture

```
QuantumConsciousnessProcessor (vLLM LogitsProcessor)
│
├── EntropySource (abstract)          — provides raw QRNG bytes
│   ├── GrpcEntropySource             — production: gRPC to QRNG server
│   ├── OsUrandomSource               — fallback: os.urandom()
│   ├── MockUniformSource             — testing: configurable mean
│   └── FallbackEntropySource         — wrapper: tries primary, falls back
│
├── SignalAmplifier (abstract)        — converts bytes to uniform float
│   └── ZScoreMeanAmplifier           — z-score of sample mean → normal CDF
│
├── TemperatureStrategy (abstract)    — computes per-token temperature
│   ├── FixedTemperatureStrategy      — constant temperature
│   └── EDTTemperatureStrategy        — entropy-based dynamic temperature
│
├── TokenSelector                     — CDF-based token selection
│   └── top-k → softmax → top-p → descending CDF → binary search
│
└── SamplingLogger                    — structured per-token logging
```

All components are constructed via a **registry-based factory** (`factory.py`). New implementations can be added by registering a class — no existing code needs to change.

## Extending the plugin

### Adding a new signal amplification algorithm

```python
from qc_sampler.signal_amplifier import SignalAmplifier, AmplificationResult
from qc_sampler.factory import register_signal_amplifier

class MyAmplifier(SignalAmplifier):
    def __init__(self, config):
        self._config = config

    def amplify(self, raw_bytes: bytes) -> AmplificationResult:
        # Your algorithm here
        return AmplificationResult(u=0.5, diagnostics={})

register_signal_amplifier("my_amplifier", MyAmplifier)
```

Then use it: `extra_args={"qc_signal_amplifier_type": "my_amplifier"}`

### Adding a new temperature strategy

```python
from qc_sampler.temperature_strategy import TemperatureStrategy, TemperatureResult
from qc_sampler.factory import register_temperature_strategy

class MyTempStrategy(TemperatureStrategy):
    def compute_temperature(self, logits, config):
        # Your formula here
        return TemperatureResult(temperature=1.0, shannon_entropy=0.0, diagnostics={})

register_temperature_strategy("my_strategy", MyTempStrategy)
```

### Adding a new entropy source

```python
from qc_sampler.entropy_source import EntropySource
from qc_sampler.factory import register_entropy_source

class MyEntropySource(EntropySource):
    def get_bytes(self, count: int) -> bytes:
        # Your implementation
        pass

    def prefetch(self, count: int) -> None:
        pass

    def health_check(self) -> dict:
        return {"source": "my_source", "status": "healthy"}

register_entropy_source("my_source", MyEntropySource)
```

## Theory: signal amplification

The z-score mean amplifier works by exploiting the central limit theorem:

- **20,480 bytes** from the QRNG are interpreted as uint8 values (0-255)
- The **sample mean** M of these values is computed
- Under the null hypothesis (truly uniform random), M follows a normal distribution with mean 127.5 and standard error `73.6116 / sqrt(20480) ≈ 0.5143`
- The **z-score** `(M - 127.5) / SEM` measures how many standard errors M is from the expected mean
- The **normal CDF** converts the z-score to a uniform value u in (0, 1)

If consciousness can bias the QRNG output even slightly (say, shifting the per-byte mean by 0.003), the z-score aggregates this across all 20,480 samples. A mean shift of 0.43 (from 127.5 to 127.93) produces u ≈ 0.80, which consistently selects less-probable (more creative/surprising) tokens from the descending-probability CDF.

## License

See LICENSE file for details.
