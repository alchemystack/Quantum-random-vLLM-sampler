# Docker Compose for vLLM with qr-sampler plugin.
#
# By default, this runs vLLM with system entropy (os.urandom) â€” no
# external entropy server is needed. To connect to an external entropy
# source, use a deployment profile's .env file.
#
# Quick start (system entropy):
#   docker compose up --build
#
# With a deployment profile (e.g. an external QRNG server):
#   docker compose --env-file ../../deployments/firefly-1/.env up --build
#
# With a profile that adds services (e.g. urandom gRPC server):
#   docker compose -f docker-compose.yml \
#     -f ../../deployments/urandom/docker-compose.override.yml \
#     --env-file ../../deployments/urandom/.env up --build
#
# Notes:
#   - Requires a GPU. Remove 'deploy.resources' to test on CPU
#     (vLLM will fall back to CPU mode for some models).
#   - Set HF_TOKEN in your environment or .env for gated models.
#   - Adjust HF_MODEL to the Hugging Face model you want to serve.

services:
  # ------------------------------------------------------------------
  # vLLM inference server with qr-sampler plugin
  # ------------------------------------------------------------------
  vllm:
    build:
      context: ../..
      dockerfile: examples/docker/Dockerfile.vllm
    ports:
      - "${VLLM_PORT:-8000}:8000"
    environment:
      # --- qr-sampler configuration ---
      # Default: system entropy (os.urandom). Override via --env-file
      # from a deployment profile to use quantum_grpc or other sources.
      QR_ENTROPY_SOURCE_TYPE: "${QR_ENTROPY_SOURCE_TYPE:-system}"
      QR_GRPC_SERVER_ADDRESS: "${QR_GRPC_SERVER_ADDRESS:-localhost:50051}"
      QR_GRPC_MODE: "${QR_GRPC_MODE:-unary}"
      QR_GRPC_TIMEOUT_MS: "${QR_GRPC_TIMEOUT_MS:-5000}"
      QR_GRPC_METHOD_PATH: "${QR_GRPC_METHOD_PATH:-/qr_entropy.EntropyService/GetEntropy}"
      QR_GRPC_STREAM_METHOD_PATH: "${QR_GRPC_STREAM_METHOD_PATH-/qr_entropy.EntropyService/StreamEntropy}"
      QR_GRPC_API_KEY: "${QR_GRPC_API_KEY:-}"
      QR_GRPC_API_KEY_HEADER: "${QR_GRPC_API_KEY_HEADER:-api-key}"
      QR_FALLBACK_MODE: "${QR_FALLBACK_MODE:-system}"
      QR_SAMPLE_COUNT: "${QR_SAMPLE_COUNT:-20480}"
      QR_TEMPERATURE_STRATEGY: "${QR_TEMPERATURE_STRATEGY:-fixed}"
      QR_FIXED_TEMPERATURE: "${QR_FIXED_TEMPERATURE:-0.7}"
      QR_TOP_K: "${QR_TOP_K:-50}"
      QR_TOP_P: "${QR_TOP_P:-0.9}"
      QR_LOG_LEVEL: "${QR_LOG_LEVEL:-summary}"

      # --- Hugging Face model to serve ---
      HF_MODEL: "${HF_MODEL:-meta-llama/Llama-3.2-1B}"
      HF_TOKEN: "${HF_TOKEN:-}"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
